{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, fbeta_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "        \n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "np.random.seed(42)  \n",
    "\n",
    "data = pd.read_csv(\"data/TCGAdata.txt\", sep=\" \")\n",
    "labels = pd.read_csv(\"data/TCGAlabels\", sep=\" \")\n",
    "\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = [\n",
    "    (\"k-Nearest Neighbors (k=3)\", KNeighborsClassifier, {\"n_neighbors\": 3}),\n",
    "    (\"Decision Tree\", DecisionTreeClassifier, {\"max_depth\": 7}),\n",
    "    (\"k-Nearest Neighbors (k=100)\", KNeighborsClassifier, {\"n_neighbors\": 100}),\n",
    "]\n",
    "\n",
    "num_principal_components = range(1, 20)\n",
    "\n",
    "# scale the data for PCA\n",
    "data = StandardScaler().fit_transform(data)\n",
    "\n",
    "# scale data with min-max scaler for variance threshold\n",
    "min_max_scaler = MinMaxScaler()\n",
    "scaled_data = min_max_scaler.fit_transform(data)\n",
    "\n",
    "BETA = 1\n",
    "cross_val_scoring = make_scorer(fbeta_score, beta=BETA, average=\"macro\", response_method=\"predict\", pos_label=None)\n",
    "cross_val_scoring = \"accuracy\"\n",
    "\n",
    "for test_size in [0.2]: #, 0.4, 0.8]:\n",
    "    \n",
    "    \n",
    "    for name, classifier_class, params in classifiers:\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=test_size, random_state=42)\n",
    "        X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(scaled_data, labels, test_size=test_size, random_state=42)\n",
    "        \n",
    "        print(f\"train size: {len(X_train)} ({(1 - test_size)*100}%) test size: {len(X_test)} ({(test_size)*100}%)\")\n",
    "        best_pca_score = 0\n",
    "        best_pca_num_components = 0\n",
    "        \n",
    "        best_var_score = 0\n",
    "        best_var_threshold = 0\n",
    "        for num_compontents in num_principal_components:\n",
    "            # Fit PCA\n",
    "            pipeline = make_pipeline(PCA(n_components=num_compontents), classifier_class(**params))\n",
    "\n",
    "            # Evaluate classifier\n",
    "            # classifier = classifier_class(**params)\n",
    "            scores = cross_val_score(pipeline, X_train , y_train.values.ravel(), cv=5, scoring=cross_val_scoring)\n",
    "            \n",
    "            scores = scores.mean()\n",
    "            if scores > best_pca_score:\n",
    "                best_pca_score = scores\n",
    "                best_pca_num_components = num_compontents\n",
    "        \n",
    "        # re run with best parameters and compare cross-validation score, train score against test\n",
    "        pca = PCA(n_components=best_pca_num_components)\n",
    "        pca.fit(X_train)\n",
    "        X_train_pca = pca.transform(X_train)\n",
    "        X_test_pca = pca.transform(X_test)\n",
    "        classifier = classifier_class(**params)\n",
    "        score = cross_val_score(classifier, X_train_pca, y_train.values.ravel(), cv=5, scoring=cross_val_scoring).mean()\n",
    "        \n",
    "        classifier.fit(X_train_pca, y_train.values.ravel())\n",
    "        train_score = fbeta_score(y_train, classifier.predict(X_train_pca), average=None, beta=BETA)\n",
    "        test_score = fbeta_score(y_test, classifier.predict(X_test_pca), average=None, beta=BETA)\n",
    "        \n",
    "        # print(f\"{name} with {best_pca_num_components} principal components: \")\n",
    "        # print(\"F SCORES:\")\n",
    "        # print(f\"Cross-validation error: {1 - score}, Train error: {1 - train_score}, Test error: {1 - test_score}\")\n",
    "        # print()\n",
    "        \n",
    "        # score = cross_val_score(classifier, X_train_pca, y_train.values.ravel(), cv=5).mean()\n",
    "\n",
    "        # classifier = classifier_class(**params)\n",
    "        # classifier.fit(X_train_pca, y_train.values.ravel())\n",
    "        # train_score = accuracy_score(y_train, classifier.predict(X_train_pca))\n",
    "        # test_score = accuracy_score(y_test, classifier.predict(X_test_pca))\n",
    "        \n",
    "        # print(\"ACCURACY SCORES:\")\n",
    "        # print(f\"Cross-validation error: {1 - score}, Train error: {1 - train_score}, Test error: {1 - test_score}\")\n",
    "        # print()\n",
    "        \n",
    "\n",
    "        print(f\"{name} : test_score: {test_score} train_score: {train_score}\")\n",
    "\n",
    "        cm = confusion_matrix(y_test, classifier.predict(X_test_pca))\n",
    "\n",
    "\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                    display_labels=classifier.classes_)\n",
    "        disp.plot()\n",
    "        disp.ax_.set_title(name)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
